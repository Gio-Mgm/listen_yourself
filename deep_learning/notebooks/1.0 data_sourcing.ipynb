{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading fer2013.zip to ../data/01/tmp\n",
      " 98%|█████████████████████████████████████▏| 59.0M/60.3M [00:01<00:00, 42.0MB/s]\n",
      "100%|██████████████████████████████████████| 60.3M/60.3M [00:01<00:00, 40.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "#! kaggle datasets download -p ../data/01/tmp --unzip -d msambare/fer2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge test and train folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! cd ../data/01/ && mkdir fer_2013 && cp -R tmp/test/* tmp/train/* fer_2013 && rm -rf ./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the dataframe and save it to a feather file\n",
    "It contains the paths of the images and their corresponding class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe saved !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "data_folder = '../data/01/fer_2013'\n",
    "classes = os.listdir(data_folder)\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for cls in classes:\n",
    "    # get all the images from this class\n",
    "    class_files = glob(os.path.join(data_folder, f'{cls}/**.jpg'))\n",
    "    # temporary dataframe\n",
    "    tmp_df = pd.DataFrame()\n",
    "    # use the dataset folder (fer_2013/) as root for the paths\n",
    "    tmp_df[\"file\"] = class_files\n",
    "    tmp_df['filename'] = [os.path.basename(f).strip('.jpg') for f in class_files]\n",
    "    tmp_df[\"target\"] = cls\n",
    "    # concatenate the dataframes\n",
    "    df = pd.concat([df, tmp_df])\n",
    "# reset index after concatenation\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# save the dataframe into a feather file \n",
    "df.to_feather(f'{data_folder}.feather')\n",
    "\n",
    "print(\"Dataframe saved !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save into SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "df_01 = pd.read_feather('../data/01/fer_2013.feather')\n",
    "# Create a connection to the SQLite database\n",
    "conn = sqlite3.connect('db_analytic.sqlite')\n",
    "\n",
    "df_01.to_sql('file', conn, if_exists='replace', index=False)\n",
    "\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_feather(os.path.join(data_root, 'fer_2013.feather'))\n",
    "# conn = sqlite3.connect('db_analytic.sqlite')\n",
    "# df = pd.read_sql_query('SELECT * FROM file', conn)\n",
    "# conn.close()\n",
    "# print(df.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4358b6f360619da83eac0dbe037ffcde9bdb72868e333523db30165e750db86d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
